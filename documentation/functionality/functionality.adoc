= Functionality
:toc:

Some images to illustrate renderer functionality.

== Cornell box

It doesn't look much to the world, but it is the hello world of path tracing.
It is used to show the pathtracer (as opposed to raytracer) features out of the box such as area lights, soft shadows, corner shadows, and color bleeding from nearby surfaces.
It do also show the lack of point (and very small) lights that is out of the box features for raytracing.

Just look at 'em bleed'n walls!

.The classic Cornell box. Color bleeding.
image::cornellbox.png[Cornell box]

.Cornell box image details
----
Image size:             800x400
Amount samples/pixel:   65536
Max recursion depth:    8
Amount facets:          18
Amount spheres:         2
Frame render time: 22h59m38.170794209s
----

== Primitives

I have implemented three types of primitives for my raytracer: triangles, spheres, and discs.

.The primitives implemented: triangles, spheres, and discs
image::primitive_display.png[The primitives triangle, sphere, and disc]
.Primitives image details
----
Image size:             1600x600
Amount samples/pixel:   8192
Max recursion depth:    4
Amount facets:          154807 (1 triangle, room, and 3 detailed Gophers)
Amount spheres:         1
Amount discs:           1
Frame render time: 10h48m1.2195545s
----

A short animation can be found at https://vimeo.com/803459254[Vimeo] (it should be played in a loop though).

== Monte Carlo Integration

As the pathtracer sends multiple rays through each pixel and each ray bounces and take a different path than the other, some rays hit a light source and others do not. The resulting light (or lack thereof) of each ray is accumulated for the pixel and averaged.
The process is called Monte Carlo Integration and for each pixel ray fired and result included in the average, the closer to the perfect intensity value for the pixel.

The Monte Carlo integration is a calculation intense process. It is not clear on what amount of integration samples (rays per pixel). The integration error (pixel intensity noise) is only halved as the amount of rays per pixel is doubled (and with that doubled rendering time, as it follow linear to the amount of rays fired).

.Cornell box at different amount of Monte Carlo integration samples (rays per pixel). (Cosine weighted hemisphere importance sampling is used.)
image::MonteCarloIntegration.png[Cornell box at different amount of Monte Carlo integration samples (rays per pixel)]

.Monte Carlo integration with different amount samples (rays per pixel) details
----
Image size:             400x200
Amount samples/pixel:   1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384
Max recursion depth:    4
Amount facets:          18
Amount spheres:         2
Frame render time:      3.65s (    1 sample/ray per pixel)
Frame render time:   3m49.05s ( 1024 samples/rays per pixel)
Frame render time: 1h0m37.03s (16384 samples/rays per pixel)
----

== Importance sampling - Cosine weighted hemisphere

In the recursive step of firing a new ray from an intersection point on a perfect diffuse object you should sample the hemisphere (around the intersection normal) uniformly or even randomly for a perfect diffuse result. However, as the light coming from that ray will be multiplied by the cosine value of the angle between the intersection normal and the ray heading vector (incoming light at low angles are do not contribute much light at all to the intersection point) the rays fired close to the normal will contribute a whooping lot more than the rays close to the intersection point tangent plane.

So, instead of firing a lot of rays from the intersection point where a lot of the only will contribute a minuscule to the Monte Carlo integration sum, we do not multiply the rays by the angle cosine value. Instead, we weigh all the rays equally much but make sure we fire rays close to the intersection normal, that will give a lot of contribution, more often and fire those close to the intersection point tangent plane more seldom, in a cosine distribution way. Given a infinite amount samples it will turn out, mathematically, the same but the cosine weighted distribution will converge faster.

.Uniform random distribution sampling of the intersection point hemisphere. Using 4 samples per pixel.
image::cornellbox_diffuse_random_hemisphere.png[Random sampled hemisphere. 4 samples/pixel.]

.Cosine weighted sampling of the intersection point hemisphere. Using 4 samples per pixel. The faster convergence is shown in comparison to the uniform random sampled hemisphere.
image::cornellbox_diffuse_cosine_weighted_hemisphere.png[Cosine weighted hemisphere sampling. 4 samples/pixel.]

.Uniform random and cosine weighted sampling of hemisphere image
----
Image size:             800x400
Amount samples/pixel:   4
Max recursion:          4
Amount spheres:         3
----

== Material - Reflection Fresnel (dielectric/non-conducting)

Work in progress (WIP)

Fresnel reflections at low gracing angles on objects.

I based my implementation on a Schlick approximation.

.Light green spheres with fresnel and glossy reflection. Increasing refraction index from left 1.000273 (air) to right 2.417 (diamond) and increasing glossiness from bottom 0.0 to top 1.0.
image::reflective_test_refractionindex_glossiness.png[Fresnel reflection with different refraction indicies and levels of glossiness]

.Fresnel and glossy image details
----
Image size:             1350x900
Amount samples/pixel:   12288
Max recursion depth:    6
Amount facets:          18
Amount spheres:         49
----

.Fresnel reflection angle. Reflection increases at the very edge of the sphere (low gracing angle). The surrounding medium is air and the sphere is white with refraction index of porcelain (refraction index 1.504).
image::fresnel_angle_refind1.504.png[Fresnel reflection using refraction index 1.504]

.Fresnel angle image details
----
Image size:             800x600
Amount samples/pixel:   12288
Max recursion depth:    4
Amount facets:          256
Amount spheres:         2
Refreaction index:      1.504 (porcelain)
----

.Fresnel reflection. Left sphere has refraction index 1.495 (Acrylic plastic). Note that the reflection increases at the very edge on the top of the left sphere (low gracing angle). (Right sphere has no Fresnel as it has the same refraction index as the surrounding air, but has common glossiness and roughness instead.)
image::fresnel_refind1.495.png[Fresnel reflection using refraction index 1.495]

.Fresnel image details
----
Image size:             800x500
Amount samples/pixel:   36864
Max recursion depth:    8
Amount facets:          12
Amount spheres:         2
Refreaction index:      1.495 (acrylic plastic)
----

== Material - Reflection Fresnel (conductor/metal)

Work in progress (WIP)

== Material - Reflection (glossy and roughness)

Reflection is not just a single "mirror" parameter on materials, but it is split in two parameters to simulate metal properties. The two parameters are "*glossiness*" and "*roughness*".

_Glossiness_ is the parameter that is the common "mirror" parameter that most tracers implement, that is the normal reflection control. A value of 0.0 is no mirrorness at all and a value of 1.0 can give a perfect mirror (depending on the roughness value).

_Roughness_ is how rough the mirror surface is, much like the real world material "brushed aluminum". It gives a non-sharp reflection. Roughness 0.0 is perfect clear mirror reflection and for roughness 1.0 it is the same as diffuse reflection.
A material with roughness 1.0 do not differ from a perfectly diffuse material, although it has full (1.0) glossiness.

.Light green sphere with reflective parameters glossiness and roughness. Glossiness increasing from left 0.0 to right 1.0 and roughness increasing from bottom 0.0 to top 1.0.
image::reflective_test_glossy_roughness.png[Reflective parameters glossiness and roughness]

.Reflection image details
----
Image size:             1350x900
Amount samples/pixel:   12288
Max recursion depth:    6
Amount facets:          18
Amount spheres:         49
----

.A Cornell box with "metallic like" settings.
image::reflection_metallic_cornellbox.png[Cornell box with metallic settings]

.Metallic cornell box details
----
Image size:        800x500
Amount samples:    1800
Max recursion:     6
Amount facets:     18
Amount spheres:    5
Total execution time: 14h6m26.331560583s
----

A short animation can be found at https://vimeo.com/758989253[Vimeo] (it should be played in a loop though).

== Depth of Field (DOF)

Depth of Field with a configurable aperture at the camera.
The depth of field depends on both aperture size (radius) and focal length.

Read the details on xref:dof/dof.adoc[how DOF is implemented].

.Depth of field using aperture 12.0 (in units, not actual 12f as in camera lenses) and "view plane distance" (the distance to perfect focus point) 2000.
[cols=">a,<a", frame=none, grid=none]
|===
|image::dof/dof_01.png[alt="Depth of field (none)"]
|image::dof/dof_02.png[alt="Depth of field"]
|===

.DOF Image details
----
Image size:             800x400
Amount samples/pixel:   2048
Max recursion:          4
Amount spheres:         6
Frame render time: 3h46m48.561010458s
----

== Aperture shape

A funny and fancy, but not so useful, feature is the ability to change the aperture shape.
This will have effect in "night shots", much like as in movies with the soft blur out of focus shapes of lights at night.

A round aperture gives round blur shapes and other shapes of the aperture will give... other shapes.

Note that out of focus in the foreground gives the shape upside down and flipped left with right, while out of focus in the background will give shapes "correct" as in the aperture.

Read the details on xref:dof/dof.adoc[how DOF and free aperture shape is implemented].

.Different aperture shapes for a matrix of luminous balls
image::dof/aperture_shape.png[Different aperture shapes]

A short animation with luminous balls and a star shaped aperture can be found at https://vimeo.com/801995169[Vimeo] (it should be played in a loop though).

== Image projection - Spherical

Spherical projection is made from equirectangular images and allow for an image to be projected onto an object from all angles.

A nifty feature is that you can place your actual scene (objects), camera and lighting within a sphere with spherical projection and you will get an environmental projection dome (sphere) as background.

Note that most of the equirectangular images are twice as wide as they are high.
There are 360 degrees around the sphere and half the amount of degrees (180) from the bottom to the top. As long as the texture image has the proportion 1:2 then the "pixels" of texture will be square (proportion 1:1) at the equator.

.Spherical projection.
image::projection_spherical.png[Spherical projection]

.Spherical projection as environmental projection on a large enclosing sphere
image::projection_spherical_environment.png[Spherical projection - environmental projection]
.Image details
----
Amount samples/pixel:   1024
Max recursion:          8
Amount spheres:         4688
----

== Image projection - Cylindrical

Cylindrical projection can be used from any image that is wrapped around a cylinder.

.Cylindrical projection
image::projection_cylindrical.png[Cylindrical projection]

.Image details
----
Image size:             960x1200
Amount samples/pixel:   12288
Max recursion depth:    4
Amount facets:          104396
Amount spheres:         2
Frame render time: 12h5m47.523553625s
----

== Image projection - Parallel

Parallel projection can be used from any image that is plainly/straight projected onto a surface.

.Parallel projection. A circular disc and three spheres, all with parallel projection. One sphere share the exact same projection as the disc. The second has a checker pattern and the third has a tree rings pattern projected on them from different angles.
image::projection_parallel.png[Parallel projection]

